\chapter{آزمایش‌ها و نتایج}
\clearpage

در این فصل ابتدا به معرفی مجموعه داده‌های استفاده شده در انجام آزمایش‌ها می‌پردازیم. سپس به بررسی آزمایش‌های انجام شده و نتایج به‌دست‌آمده از ارزیابی مدل پیشنهادی می‌پردازیم و نتایج حاصل را مورد بررسی قرار می‌دهیم.

به‌طور کلی، آزمایش‌های انجام شده در این پژوهش را می‌توان به دو دسته تقسیم کرد:
\begin{enumerate}
    \item پیش‌آموزش خودنظارتی بر روی مجموعه داده‌ی کوچک و تنظیم دقیق بر روی همان مجموعه.
    \item پیش‌آموزش خودنظارتی بر روی مجموعه داده‌ی بزرگ و تنظیم دقیق بر روی مجموعه داده‌ی کوچک.
\end{enumerate}

\section{مجموعه داده}

برای ارزیابی عملکرد روش پیشنهادی در این پژوهش، از دو مجموعه داده \lr{HAPT\LTRfootnote{Smartphone-Based Recognition of Human Activities and Postural Transitions}}\cite{reyes2015smartphone}
(مجموعه داده کوچک) و
\lr{MobiAct}\cite{vavoulas2016mobiact}
(مجموعه داده بزرگ)
استفاده کردیم. در ادامه، جزئیات هر یک از این مجموعه داده‌ها به تفصیل تشریح می‌شود.

\subsection{مجموعه داده \lr{HAPT}}

مجموعه داده \lr{HAPT}
یکی از مجموعه داده‌های شناخته‌شده و پرکاربرد در حوزه شناسایی فعالیت انسان است که در دسترس عموم قرار دارد. این مجموعه داده نسخه توسعه‌یافته و کامل‌تری از مجموعه داده
\lr{UCI-HAR}\cite{anguita2013public}
است و علاوه بر فعالیت‌های پایه، شامل گذارهای وضعیتی\LTRfootnote{Postural Transitions} نیز می‌شود.

هدف اصلی از ایجاد این مجموعه داده، فراهم کردن داده‌های خام و پردازش‌شده از حسگرهای اینرسی تعبیه‌شده در گوشی‌های هوشمند برای ساخت و ارزیابی مدل‌های شناسایی فعالیت است. تمرکز ویژه این مجموعه داده بر تمایز قائل شدن بین فعالیت‌های ایستا و پویا و همچنین شناسایی حرکات کوتاه و انتقالی بین حالت‌های ایستا است.

\begin{figure}[htb!]
\centering
\includegraphics[width=0.75\textwidth]{Images/Chapter4/hapt-classes.png}
\caption{دسته‌های مختلف مجموعه داده \lr{HAPT}}
\label{fig:hapt-classes}
\end{figure}

داده‌های این مجموعه از ۳۰ داوطلب در بازه سنی ۱۹ تا ۴۸ سال جمع‌آوری شده است. هر شرکت‌کننده یک گوشی هوشمند \lr{Samsung Galaxy S II} را بر روی کمر خود بسته بود و رویه مشخصی از فعالیت‌ها را انجام می‌داد. تمام آزمایش‌ها به صورت ویدیویی ضبط شدند تا برچسب‌گذاری داده‌ها با دقت بالایی به صورت دستی انجام شود.

داده‌ها از دو حسگر اصلی گوشی هوشمند استخراج شده‌اند: حسگر شتاب‌سنج که سیگنال شتاب خطی سه‌محوره و حسگر ژیروسکوپ که سیگنال سرعت زاویه‌ای سه‌محوره را ثبت می‌کند. نرخ نمونه‌برداری برای هر دو حسگر ۵۰ هرتز بوده است.

همانطور که در شکل \ref{fig:hapt-classes}
می‌توان دید، این مجموعه داده شامل ۱۲ کلاس فعالیت مجزا است که به دو دسته اصلی تقسیم می‌شوند:
\begin{itemize}
    \item فعالیت‌های پایه که خود شامل سه فعالیت ایستای ایستادن، نشستن و دراز کشیدن و سه فعالیت پویای راه رفتن، بالا رفتن از پله و پایین آمدن از پله می‌باشد.
    \item گذارهای وضعیتی که شامل حرکات انتقالی بین فعالیت‌های ایستا می‌باشد و دارای فعالیت‌های ایستادن به نشستن، نشستن به ایستادن، نشستن به دراز کشیدن، دراز کشیدن به نشستن، ایستادن به دراز کشیدن و دراز کشیدن به ایستادن می‌باشد.
\end{itemize}

مجموعه داده \lr{HAPT} هم به صورت داده‌های خام حسگر و هم به صورت ویژگی‌های استخراج‌شده ارائه می‌گردد. داده‌های خام شامل سیگنال‌های سه‌محوره شتاب‌سنج و ژیروسکوپ به صورت سری زمانی است که نتیجتا شامل ۶ ویژگی می‌باشد. ویژگی‌های استخراج شده نیز بدین صورت می‌باشند که ابتدا سیگنال‌های خام با استفاده از یک پنجره لغزان به طول ۱۲۸ (۵۶.۲ ثانیه) و ۵۰ درصد همپوشانی قطعه‌بندی شده‌اند. از هر قطعه، یک بردار ویژگی ۵۶۱ بعدی استخراج شده است. این ویژگی‌ها شامل محاسبات آماری در حوزه زمان و فرکانس مانند میانگین، انحراف معیار، تبدیل فوریه سریع و غیره هستند. در این پژوهش از سیگنال‌های خام حسگرها برای آموزش مدل استفاده کردیم.

\subsection{مجموعه داده \lr{MobiAct}}

مجموعه داده \lr{MobiAct}
یک مجموعه داده عمومی برای شناسایی فعالیت انسان  است که با استفاده از حسگرهای گوشی هوشمند ایجاد شده و به طور خاص بر تشخیص فعالیت‌های روزمره و انواع سقوط\LTRfootnote{Falls}
تمرکز دارد. این مجموعه داده شامل داده‌های ثبت‌شده از سه حسگر اصلی یک گوشی هوشمند \lr{Samsung Galaxy S III}
یعنی شتاب‌سنج، ژیروسکوپ و حسگر جهت‌یاب\LTRfootnote{Orientation Sensor} می‌باشد.

داده‌ها از ۵۷ داوطلب (۴۲ مرد و ۱۵ زن) با میانگین سنی ۲۶ سال جمع‌آوری شده است. از این تعداد، ۵۰ شرکت‌کننده تمام سناریوهای مربوط به فعالیت‌های روزمره و ۵۴ شرکت‌کننده تمام سناریوهای سقوط را با موفقیت به پایان رساندند. برای شبیه‌سازی هرچه بهتر شرایط واقعی، از هر شرکت‌کننده خواسته شد تا گوشی هوشمند را به صورت آزاد و با جهت‌گیری دلخواه در جیب شلوار خود قرار دهد.

فعالیت‌های ثبت‌شده در این مجموعه داده به دو گروه اصلی تقسیم می‌شوند:
\begin{itemize}
    \item\textbf{نه نوع فعالیت روزمره:}  این فعالیت‌ها شامل ایستادن، راه رفتن، دویدن، پریدن، بالا رفتن از پله، پایین آمدن از پله، نشستن روی صندلی، وارد شدن به ماشین و خارج شدن از ماشین است.
    \item\textbf{چهار نوع سقوط شبیه‌سازی‌شده:}  این سقوط‌ها شامل سقوط به جلو، سقوط به جلو روی زانو، سقوط به پهلو و سقوط به عقب در حین تلاش برای نشستن روی صندلی می‌باشند.
\end{itemize}

\section{جزئیات پیاده‌سازی}

در این بخش به بررسی جزئیات مختلف پیاده‌سازی روش پیشنهادی (شامل پیش‌پردازش داده‌ها، آموزش مدل و معیارهای ارزیابی) می‌پردازیم.

\subsection{پیش‌پردازش داده‌ها}

پیش‌پردازش داده‌ها یک مرحله مهم در آموزش مدل‌های شناسایی فعالیت انسان است و عملکرد چشم‌گیری در بهبود نتایج به همراه دارد. برای این امر، ابتدا بایستی که داده‌ها را نرمال‌سازی کنیم. برای نرمال‌سازی داده‌ها از روش استانداردسازی که به آن نرمال‌سازی \lr{Z-score} نیز می‌گویند استفاده می‌کنیم. فرمول آن به فرم زیر است:
\begin{equation}
    z=\frac{x-\mu}{\sigma}
\end{equation}
در این رابطه $x$ بیانگر مقدار هر داده، $\mu$ بیانگر میانگین توزیع داده‌ها و $\sigma$ انحراف معیار توزیع داده‌ها می‌باشند. با استفاده از استانداردسازی، میانگین توزیع داده‌ها برابر با صفر و انحراف معیار آن‌ها برابر با یک می‌شود.

نکته‌ی مهم در رابطه با نرمال‌سازی داده‌ها این است که اگر ابتدا داده‌ی خام سیگنال‌ها را استانداردسازی کنیم و سپس تبدیل موجک را اعمال کنیم، تبدیل موجک حاصل همانطور که در شکل \ref{fig:unnormalized-wavelet}
می‌توان دید، در جاهایی که موجک استفاده شده با داده‌ی سری زمانی ورودی همبستگی بالا داشته باشد، بازه‌ی اسکالوگرام خروجی بزرگ می‌گردد و می‌تواند تا چند برابر بیشتر از داده‌ی خام سیگنال شود. به‌همین منظور، داده‌ی خام سیگنال‌ها  استانداردسازی می‌شوند و داده‌ی اسکالوگرام‌ها به‌صورت مستقل از یکدیگر استانداردسازی می‌شوند. پس از استانداردسازی داده‌ها می‌توانیم از آن‌ها برای پیش‌آموزش و آموزش مدل استفاده کنیم.

\begin{figure}[htb!]
\centering
\includegraphics[width=0.75\textwidth]{Images/Chapter4/unnormalized-wavelet.png}
\caption{تاثیر تبدیل موجک بر برد اسکالوگرام خروجی}
\label{fig:unnormalized-wavelet}
\end{figure}

پس از نرمال‌سازی داده‌ها، به سراغ پر کردن مقادیر از دست رفته‌ی سیگنال‌ها با استفاده از درون‌یابی\LTRfootnote{Interpolation} می‌رویم. هر چند که هیچ یک از دو مجموعه داده‌ی استفاده شده در این پژوهش مقادیر از دست رفته ندارند، اما در هر حال می‌توان با درون‌یابی به آن‌ها رسیدگی کرد.

در قدم بعدی، بایستی نرخ نمونه‌برداری مجموعه داده‌ها را کنترل کنیم. در حالتی که هم پیش‌آموزش خودنظارتی و هم تنظیم دقیق بر روی یک مجموعه داده انجام می‌شود، نیازی به این موضوع نیست و نرخ نمونه‌برداری را همان ۵۰ هرتز
برای مجموعه داده \lr{HAPT}
نگاه می‌داریم. اما هنگامی که پیش‌آموزش بر روی مجموعه داده \lr{MobiAct}
انجام می‌شود و تنظیم دقیق بر روی \lr{HAPT}،
بایستی که هر دو مجموعه داده دارای نرخ نمونه‌برداری برابر باشند. چرا که به‌عنوان مثال اگر از یک پنجره به طول ۱۰۰ استفاده کنیم، در حالتی که نرخ نمونه‌برداری ۵۰ هرتز است، به فعالیت‌های انجام شده در یک بازه‌ی ۲ ثانیه‌ای نگاه می‌کنیم. اما هنگامی که نرخ نمونه‌برداری ۲۰ هرتز باشد (نرخ نمونه‌برداری مجموعه داده \lr{MobiAct})،
به فعالیت‌های انجام شده در یک بازه‌ی ۵ ثانیه‌ای نگاه می‌کنیم. که این امر باعث افت عملکرد مدل می‌شود. به‌همین دلیل باید در حالتی که یادگیری انتقالی انجام می‌دهیم، نرخ نمونه‌برداری مجموعه داده \lr{HAPT} را نیز به ۲۰ هرتز برسانیم تا با مجموعه داده \lr{MobiAct}
هماهنگ شود.

سپس داده‌ها را به پنجره‌های لغزان به طول ۱۲۸ و دارای همپوشانی تقسیم می‌کنیم. در رابطه با مجموعه داده \lr{HAPT} به‌علت کم بودن تعداد داده‌ها میزان همپوشانی را برابر با ۹۰ درصد قرار دادیم. اما برای مجموعه داده \lr{MobiAct} میزان همپوشانی را برابر با ۵۰ درصد قرار دادیم. در تنظیم دقیق دارای نظارت نیز برچسب هر پنجره برابر با برچسبی است که بیشترین تعداد تکرار را دارد.

\subsection{آموزش مدل}

آموزش مدل شامل دو بخش پیش‌آموزش خودنظارتی و تنظیم دقیق دارای نظارت می‌باشد. در بخش پیش‌آموزش مدل، از تمام داده‌های موجود در مجموعه داده استفاده می‌کنیم. چرا که از برچسب داده‌ها استفاده‌ای نکرده‌ایم و صرفا هدف یادگیری توزیع داده‌ها و تولید بازنمایی مفید است. بنابراین
نشت مدل\LTRfootnote{Model leakage}
رخ نمی‌دهد.

در آموزش دارای نظارت که از مجموعه داده \lr{HAPT} استفاده کرده‌ایم، مدل پیش‌آموزش دیده را با درصدهای مختلفی از داده‌ی آموزش و ارزیابی آموزش دادیم. این درصدها شامل ۸۰ درصد آموزش، ۶۰ درصد آموزش، ۴۰ درصد آموزش و ۲۰ درصد آموزش می‌باشند. در واقع هدف این است که قدرت تعمیم مدل و آموزش با میزان پایین داده‌ی آموزشی را ارزیابی کنیم.

روند انجام آزمایشات بدین صورت است که ابتدا رمزگذارهای سیگنال و اسکالوگرام را با استفاده از روشی که در فصل قبل ارائه دادیم را پیش‌آموزش می‌دهیم و وزن‌های 
رمزگذارها را ذخیره می‌کنیم. سپس در مرحله‌ی بعد، دسته‌بندها را بر روی ویژگی‌های استخراج شده از رمزگذارها با استفاده از درصدهای مختلف داده آموزشی آموزش می‌دهیم. به ازا هر درصد، ۵ بار آزمایش را به‌این صورت تکرار می‌کنیم:
\begin{enumerate}
    \item مجموعه داده را به ۵ بخش مساوی تقسیم می‌کنیم.
    \item بسته به درصد داده‌ی آموزشی و ارزیابی، تعدادی از این بخش‌ها آموزشی و تعدادی از آن‌ها ارزیابی می‌باشند.
    \item ۵ بار آزمایش را تکرار می‌کنیم و هر بار داده‌های آموزشی و ارزیابی متفاوت می‌باشند.
    \item ارزیابی نهایی عملکرد مدل برابر با میانگین ۵ بار اجرا مربوطه می‌باشد.
\end{enumerate}

\subsection{معیارهای ارزیابی}

ارزیابی عملکرد مدل‌های یکی از مهم‌ترین بخش‌های یادگیری ماشین می‌باشد. در این پژوهش از دو معیار ارزیابی امتیاز \lr{F1}\LTRfootnote{F1 Score}
و امتیاز کاپا\LTRfootnote{Kappa Score}
(که به آن کاپای کوهن\LTRfootnote{Cohen's Kappa} نیز می‌گویند) استفاده کرده‌ایم. اما پیش از بررسی این دو معیار ارزیابی، بایستی که ۳ معیار ارزیابی دیگر شامل صحت\LTRfootnote{Accuracy}، دقت\LTRfootnote{Precision} و فراخوانی\LTRfootnote{Recall} را معرفی کنیم.

معیار صحت به‌عنوان یکی از معیارهای پرکاربرد برای ارزیابی یک مدل دسته‌بندی در مسائل مختلف یادگیری ماشین مورد استفاده قرار می‌گیرد. این معیار نسبت تعداد داده‌هایی را که به درستی توسط مدل دسته‌بندی شده‌اند به تعداد کل داده‌های موجود در داده‌های آزمون می‌سنجد. فرمول محاسبه صحت به فرم معادله \ref{eq:accuracy} می‌باشد:
\begin{equation}
    \mathrm{Accuracy}=\frac{TP+TN}{TP+TN+FP+FN}
    \label{eq:accuracy}
\end{equation}
در این معادله، $TP$\LTRfootnote{True Positive} به تعداد نمونه‌های مثبت واقعی که به درستی مثبت تشخیص داده‌شده‌اند، $TN$\LTRfootnote{True Negative} به تعداد نمونه‌های منفی واقعی که به درستی منفی تشخیص داده‌شده‌اند، $FP$\LTRfootnote{False Positive} به تعداد نمونه‌های منفی واقعی که به اشتباه مثبت تشخیص داده‌شده‌اند و $FN$\LTRfootnote{False Negative} به تعداد نمونه‌های مثبت واقعی که به اشتباه به‌عنوان منفی تشخیص داده‌شده‌اند اشاره دارد.

معیار دقت بیانگر نسبت نمونه‌های مثبت واقعی که به درستی تشخیص داده‌شده‌اند به تعداد نمونه‌هایی که مدل مثبت تشخیص داده‌است می‌باشد:
\begin{equation}
    \mathrm{Precision}=\frac{TP}{TP+FP}
\end{equation}
معیار فراخوانی نیز بیانگر نسبت نمونه‌های مثبت واقعی که به درستی تشخیص داده‌شده‌اند به تعداد کل نمونه‌های مثبت واقعی است:
\begin{equation}
    \mathrm{Recall}=\frac{TP}{TP+FN}
\end{equation}
حال به بررسی معیارهای ارزیابی مورد استفاده در این پژوهش می‌پردازیم. معیار امتیاز \lr{F1}
یک معیار جامع برای ارزیابی مدل‌های دسته‌بندی است که به صورت ترکیبی از دقت و فراخوانی محاسبه می‌شود. این معیار بیشتر منعکس‌کننده‌ی توازن میان دقت و فراخوانی مدل است. فرمول محاسبه امتیاز \lr{F1} به فرم معادله \ref{eq:f1-score} می‌باشد:
\begin{equation}
    \mathrm{F1 \space Score}=2\times\frac{\mathrm{Precision}\times\mathrm{Recal}}{\mathrm{Precision}+\mathrm{Recall}}
    \label{eq:f1-score}
\end{equation}
معیار ارزیابی دیگری که در این پژوهش مورد استفاده قرار گرفته است، امتیاز کاپا می‌باشد. این معیار، میزان توافق بین پیش‌بینی‌های انجام‌شده توسط مدل و برچسب‌های واقعی را با در نظر گرفتن احتمال توافق تصادفی، ارزیابی می‌کند. مزیت اصلی امتیاز کاپا این است که نشان می‌دهد عملکرد مدل تا چه حد از یک حدس کاملاً تصادفی بهتر است. این ویژگی، کاپا را به معیاری قابل اطمینان‌تر، به‌ویژه در هنگام مواجهه با مجموعه داده‌های نامتوازن تبدیل می‌کند. فرمول محاسبه امتیاز کاپا به فرم معادله \ref{eq:kappa} می‌باشد:
\begin{equation}
\mathrm{Kappa} = \frac{\mathrm{Accuracy} - \mathrm{Accuracy_r}}{1 - \mathrm{Accuracy_r}}
\label{eq:kappa}
\end{equation}
در این معادله،
\lr{Accuracy}
همان صحت مدل است و $\mathrm{Accuracy}_r$
نشان‌دهنده‌ی صحت توافق تصادفی است. این مقدار، نمایانگر صحت عملکرد یک مدل فرضی است که تعداد پیش‌بینی‌هایش برای هر دسته، دقیقا با تعداد پیش‌بینی‌های مدل اصلی ما یکسان است، اما این تخصیص برچسب‌ها را کاملا 
به صورت تصادفی انجام می‌دهد. به عبارت دیگر، ما عملکرد مدل خود را با یک پیش‌بینی‌کننده‌ی تصادفی که از توزیع داده‌ها آگاه است، مقایسه می‌کنیم تا ببینیم یادگیری مدل چقدر فراتر از شانس بوده است. برای یک مسئله‌ی دسته‌بندی چندکلاسه با $k$
دسته، فرمول کلی محاسبه‌ی $\mathrm{Accuracy}_r$
به صورت معادله \ref{eq:acc_r_multiclass} می‌باشد:
\begin{equation}
\mathrm{Accuracy_r} = \frac{1}{N^2} \sum_{i=1}^{k} (A_i \times P_i)
\label{eq:acc_r_multiclass}
\end{equation}
در این معادله $k$ تعداد دسته‌ها، $N$ تعداد کل نمونه‌ها، $A_i$ تعداد کل نمونه‌های واقعی متعلق به دسته‌ی $i$ و $P_i$
تعداد کل نمونه‌هایی است که توسط مدل به عنوان دسته‌ی $i$ پیش‌بینی شده‌اند.

مقدار امتیاز کاپا بین ۱- و ۱+ قرار دارد. مقادیر مثبت به معنای عملکرد بهتر مدل از یک دسته‌بند تصادفی، مقدار صفر به معنای عملکرد کاملا تصادفی مدل و مقادیر منفی به معنای عملکرد بدتر مدل از یک دسته‌بند تصادفی می‌باشد.

\subsection{ابرپارامترها}

جزئیات پیکربندی مدل پیشنهادی در جدول \ref{tab:model-configs}
قابل مشاهده می‌باشد. مقادیر انتخابی بر اساس روش پایه \cite{taghanaki2023self} انتخاب شده‌اند و جستجوی گسترده‌ای برای یافتن پیکربندی بهینه انجام نشده است. تعداد خوشه‌ها برای روش \lr{SwAV} نیز به‌صورت تجربی بایستی حدود ۱۰ برابر تعداد دسته‌های مجموعه داده هدف باشند\cite{caron2020unsupervised}. بنابراین تعداد خوشه‌ها را برابر با ۱۲۸ قرار دادیم.

\begin{table}[ht]
\centering
\caption{پیکربندی یادگیرنده‌ی سیگنال (سمت راست) و یادگیرنده‌ی اسکالوگرام (سمت چپ)}
\includegraphics[width=1\textwidth]{Images/Chapter4/structure-table.png}
\label{tab:model-configs}
\end{table}

% \begin{table}[h]
% \centering
% \caption{پیکربندی یادگیرنده‌ی سیگنال (سمت راست) و یادگیرنده‌ی اسکالوگرام (سمت چپ)}
% \label{tab:model-configs}

% % ------------ جدول اول ------------
% \begin{minipage}{0.4\textwidth}
% \centering
% \renewcommand{\arraystretch}{1.2} % تنظیم فاصله عمودی بین ردیف‌ها
% \begin{tabular}{ll} % حذف خطوط عمودی
%     \toprule % خط افقی بالایی ضخیم
%     \textbf{واحد} & \textbf{جزئیات لایه} \\
%     \midrule % خط افقی میانی
%     \multirow{4}{*}{رمزگذار} & پیچشی با هسته \lr{$1 \times 12$} ۳۲ کاناله \\
%     \cline{2-2} % خط افقی فقط برای ستون دوم
%     & پیچشی با هسته \lr{$1 \times 8$} ۶۴ کاناله \\
%     \cline{2-2}
%     & پیچشی با هسته \lr{$1 \times 8$} ۹۶ کاناله \\
%     \cline{2-2}
%     & ادغام بیشینه سراسری \\
%     \midrule % خط افقی میانی
%     \multirow{2}{*}{شبکه نگاشت} & تماما متصل ۹۶ بعدی \\
%     \cline{2-2}
%     & تماما متصل ۹۶ بعدی \\
%     \midrule % خط افقی میانی
%     \multirow{2}{*}{شبکه دسته‌بند} & تماما متصل ۲۵۶ بعدی \\
%     \cline{2-2}
%     & تماما متصل ۱۲ بعدی \\
%     \bottomrule % خط افقی پایینی ضخیم
% \end{tabular}
% \end{minipage}
% \hfill % ایجاد فاصله افقی بین دو جدول
% % ------------ جدول دوم ------------
% \begin{minipage}{0.4\textwidth}
% \centering
% \renewcommand{\arraystretch}{1.2} % تنظیم فاصله عمودی بین ردیف‌ها
% \begin{tabular}{ll} % حذف خطوط عمودی
%     \toprule % خط افقی بالایی ضخیم
%     \textbf{واحد} & \textbf{جزئیات لایه} \\
%     \midrule % خط افقی میانی
%     \multirow{4}{*}{رمزگذار} & پیچشی با هسته \lr{$8 \times 8$} ۳۲ کاناله \\
%     \cline{2-2} % خط افقی فقط برای ستون دوم
%     & پیچشی با هسته \lr{$4 \times 4$} ۶۴ کاناله \\
%     \cline{2-2}
%     & پیچشی با هسته \lr{$4 \times 4$} ۹۶ کاناله \\
%     \cline{2-2}
%     & ادغام بیشینه سراسری \\
%     \midrule % خط افقی میانی
%     \multirow{2}{*}{شبکه نگاشت} & تماما متصل ۹۶ بعدی \\
%     \cline{2-2}
%     & تماما متصل ۹۶ بعدی \\
%     \midrule % خط افقی میانی
%     \multirow{2}{*}{شبکه دسته‌بند} & تماما متصل ۲۵۶ بعدی \\
%     \cline{2-2}
%     & تماما متصل ۱۲ بعدی \\
%     \bottomrule % خط افقی پایینی ضخیم
% \end{tabular}
% \end{minipage}
% \end{table}

نرخ یادگیری در بخش پیش‌آموزش خودنظارتی بدین صورت می‌باشد:
\begin{enumerate}
    \item مقدار اولیه‌ی نرخ یادگیری را برابر با $0.001$ قرار می‌دهیم.
    \item به‌صورت خطی طی ۱۰ دوره\LTRfootnote{Epoch} اول آن را تا $0.05$ افزایش می‌دهیم. مقادیر بزرگ‌تر موجب ناپایداری یادگیری می‌شوند.
    \item به صورت کسینوسی و تا آخرین دوره آموزش (۱۰۰ دوره) مقدار نرخ یادگیری را تا $0.0001$ کاهش می‌دهیم.
\end{enumerate}
برای تنظیم دقیق مدل، از یک نرخ یادگیری ثابت برابر با $0.001$ استفاده کردیم.
تعداد تکرار الگوریتم سینکهورن (که در بخش \ref{sec:sinkhorn} معرفی کردیم) برابر با ۳ می‌باشد.

مقدار ابرپارمتر $\epsilon$ (معادله \ref{eq:swav-optimal-transport}) را برابر با 0.01 قرار دادیم. افزایش مقدار این پارامتر باعث می‌شود که تخصیص‌های روش سینکهورن برای تمامی داده‌ها به تمامی خوشه‌ها یکنواخت شود که در این حالت مدل بازنمایی‌های خوبی یاد نمی‌گیرد. پارامتر دما ($\tau$ در معادله \ref{eq:swav-p-calculation}) نیز می‌تواند تاثیری مشابه داشته باشد. زیاد کردن مقدار آن باعث می‌شود که توزیع تخصیص‌ها توسط الگوریتم سینکهورن یکنواخت شود. اما بیش از حد کم کردن مقدار آن نیز شدیدا باعث ناپایداری آموزش خواهد شد. همانطور که در معادله \ref{eq:swav-p-calculation} دیده می‌شود،
مقدار موجود در نمای $exp$ تقسیم بر ابرپارمتر دما می‌شود. کوچک بودن بیش از حد این ابرپارامتر باعث می‌شود که مقدار این توان از لحاظ عددی بسیار بزرگ شود که به تبع آن کامپیوتر نمی‌تواند مقدار آن را محاسبه کند و فرآیند آموزش دچار  خطا می‌شود. بنابراین مقدار آن را برابر با مقدار 0.05 قرار دادیم که هم از یکنواخت شدن توزیع سینکهورن جلوگیری می‌کند و هم باعث ناپایداری آموزش نمی‌شود.

اندازه‌ی دسته برای داده‌های خام سیگنال را برابر با ۱۰۲۴ و برای اسکالوگرام نیز برابر با ۵۱۲ قرار دادیم. تعداد دوره‌ی آموزش در بخش پیش‌آموزش خودنظارتی را برای رمزگذار سیگنال برابر با ۱۰۰ و برای رمزگذار اسکالوگرام برابر با ۷۵ قرار دادیم. اما برای تنظیم دقیق هر دو مدل، از روش توقف زودهنگام\LTRfootnote{Early Stopping}
استفاده می‌کنیم. بدین صورت که بر روی داده‌های اعتبارسنجی، مقدار هزینه مدل را بررسی می‌کنیم و هنگامی که مدل دچار بیش‌برازش شد و هزینه‌ی اعتبارسنجی بالا رفت، آموزش را متوقف می‌کنیم و بهترین مدل را انتخاب می‌کنیم.
